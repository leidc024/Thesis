"""
AMBIGUITY COUNTING EXPLANATION

This script explains how ambiguities are counted in your dataset
and clarifies the difference between individual ambiguities vs patterns.
"""

def explain_counting():
    print("=" * 70)
    print("AMBIGUITY COUNTING: How It Actually Works")
    print("=" * 70)
    print()
    
    print("ğŸ¤” YOUR QUESTION: Is 'bote' vs 'buti' counted as 3 ambiguities?")
    print("   (2 for E/I + 1 for O/U)")
    print()
    print("ğŸ“Š ANSWER: NO - It's counted as 1 PATTERN with COMBINED type")
    print()
    
    print("ğŸ” LET'S EXAMINE THE REAL DATA:")
    print("-" * 40)
    
    # Example from your actual dataset
    examples = [
        {
            "baybayin": "áœŠáœ“áœ†áœ’",
            "words": ["bote", "buti"],
            "type": "COMBINED",
            "individual_ambiguities": ["oâ†’u (boteâ†’buto)", "eâ†’i (boteâ†’biti)"],
            "pattern_count": 1
        },
        {
            "baybayin": "áœáœƒáœ’", 
            "words": ["lake", "laki"],
            "type": "E/I",
            "individual_ambiguities": ["eâ†’i (lakeâ†’laki)"],
            "pattern_count": 1
        },
        {
            "baybayin": "áœ†áœ“áœ‡áœ“",
            "words": ["todo", "toro", "turo"],
            "type": "COMBINED",
            "individual_ambiguities": ["oâ†’u (todoâ†’tudo)", "oâ†’u (toroâ†’turu)", "dâ†’r (todoâ†’rodo)"],
            "pattern_count": 1
        }
    ]
    
    for i, ex in enumerate(examples, 1):
        print(f"{i}. PATTERN: {ex['baybayin']}")
        print(f"   Words: {' â†” '.join(ex['words'])}")
        print(f"   Classification: {ex['type']}")
        print(f"   Contains these individual ambiguities:")
        for amb in ex['individual_ambiguities']:
            print(f"     â€¢ {amb}")
        print(f"   ğŸ“Š Counted as: {ex['pattern_count']} pattern")
        print()
    
    print("=" * 70)
    print("COUNTING METHODOLOGY")
    print("=" * 70)
    print()
    
    print("ğŸ¯ PATTERN-BASED COUNTING (What your dataset uses):")
    print("   â€¢ Each unique Baybayin representation = 1 pattern")
    print("   â€¢ 'bote' â†” 'buti' = 1 COMBINED pattern")
    print("   â€¢ 'lake' â†” 'laki' = 1 E/I pattern")  
    print("   â€¢ 'todo' â†” 'toro' â†” 'turo' = 1 COMBINED pattern")
    print()
    
    print("ğŸ“ˆ YOUR ACTUAL STATISTICS:")
    print("   â€¢ Total patterns: 10,122")
    print("   â€¢ E/I patterns: 465 (pure E/I only)")
    print("   â€¢ O/U patterns: 491 (pure O/U only)")
    print("   â€¢ D/R patterns: 229 (pure D/R only)")
    print("   â€¢ COMBINED patterns: 93 (mixed types)")
    print("   â€¢ UNKNOWN patterns: 8,844 (other ambiguities)")
    print()
    
    print("ğŸ” INDIVIDUAL AMBIGUITY COUNTING (Alternative view):")
    print("   If we counted each individual vowel/consonant ambiguity:")
    print("   â€¢ 'bote' â†” 'buti' would contribute:")
    print("     - 1 count to O/U (o in position 1)")
    print("     - 1 count to E/I (e in position 3)")
    print("     - Total: 2 individual ambiguities")
    print()
    
    print("âœ… WHY PATTERN COUNTING MAKES SENSE:")
    print("   â€¢ Each pattern represents 1 disambiguation challenge")
    print("   â€¢ When OCR sees 'áœŠáœ“áœ†áœ’', it faces 1 decision: bote or buti?")
    print("   â€¢ The fact that it involves both O/U and E/I is metadata")
    print("   â€¢ Your graph model needs to resolve 1 pattern, not count ambiguities")
    print()
    
    print("ğŸ“Š DATASET DISTRIBUTION TARGET:")
    print("   Your 500-sentence dataset aims for:")
    print("   â€¢ 175 sentences with E/I patterns (35%)")
    print("   â€¢ 175 sentences with O/U patterns (35%)")  
    print("   â€¢ 75 sentences with D/R patterns (15%)")
    print("   â€¢ 50 sentences with COMBINED patterns (10%)")
    print("   â€¢ 25 sentences with no ambiguity (5%)")

if __name__ == "__main__":
    explain_counting()